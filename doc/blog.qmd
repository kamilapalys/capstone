---
title: "How Differently Do News Sources Report on the Same Events?"
subtitle: "Spring 2024"
author: "Kamila Palys"
bibliography: references.bib
number-sections: false
format:
  html:
    theme: default
    rendering: embed-resources
    code-fold: true
    code-tools: true
    toc: true
  pdf: default
jupyter: python3
---


![Source: Unsplash](newspaper.jpg){fig-alt="A man reading a newspaper."}

# Introduction

Everybody at some point has been at the center of a debate or has heard one about which news sources are trustworthy or not. These opinions clearly tend to be associated with the identification of a political party. A lot of the times, these opinions are largely subjective, but can they be confirmed or changed with a more technical analysis on news sources? This project takes a closer look at the language that various news sources use and examines if these news sources really report on the same events in a different manner. This will be done mainly through sentiment analysis and creating classifiers to predict the source of a given article. 

# Data Collection

 Nine total news sites are studied for a mix of political affiliations, including CNN, The New York Times, The Washington Post, Fox News, New York Post, NBC News, The Wall Street Journal, BBC, and ABC News. Eight political events and topics from 2023 were chosen as the subjects for the articles to be studied for a higher potential for bias. For each topic, one article from each source was collected, making for a total of 72 articles. To ensure as little room for extraneous variables as possible, the articles for a particular topic across sources were chosen in a way so that they were published on the same day or as closely together in time as possible. This would mean that each source should have had the same information available when writing the article. The text from each article was collected through copying and pasting into its own text file. In addition, a string denoting each article's topic and source name was added to the end of each article's text file to be able to identify it. 

# Data Preprocessing

The text had to go through a lot of preparation before it could be ready for analyzing. Functions were created to make this process faster for each article. One function accesses a text file and returns a string of all the text in there. Another function cleans the text, which includes making all text lowercase, removing punctuation, removing stopwords (words like "and," "the," etc.), and stemming words, if desired. Stemming words keeps only the root form of a word, removing suffixes so that words like "jumps" and "jumping" are both reduced to "jump." This is desired for some parts of the analysis in this project, but not others. 

```{python}
# initialize dictionary to be able to trace back a stemmed word to its original form
stemmed_dict = {}

def file_to_string(filename):
  '''Opens the input text file and
  returns a string of all its text.'''
  file = open(filename, 'r')
  text = file.read()
  file.close()
  text = text.replace('\n', ' ')
  text = text.replace('  ', ' ')
  return text

def clean_text(text, stem):
  '''Takes in a string of text and cleans it by converting
  to lowercase, removing punctuation, and removing stopwords. 
  Also takes in a binary value to indicate if stemming should
  be performed. Returns the new string.'''
  if stem not in [0, 1]:
      raise ValueError("Stem must be a binary value (0 or 1)")
  ps = PorterStemmer()
  stemmed_dict = {}
  # create list of stopwords 
  stopwords_list = stopwords.words('english')
  # make the text lowercase
  text = text.lower()
  text = text.replace('â€”', ' ')
  text = text.replace('u.s.', 'us')
  # convert to ascii characters
  text = text.encode("ascii", "ignore").decode()
  for chr in text:
      # only keep characters in the string that are not punctuation symbols
      if (chr in string.punctuation or chr in string.digits):
          text = text.replace(chr, ' ')
  text = text.replace('  ', ' ')
  # stem the tokens within the text
  tokens = text.split()
  new_tokens = []
  for token in tokens[:-2]: # last two tokens identify source and topic, we do not want to stem them
      # only include new token in the cleaned list if not a stopword
      if token not in stopwords_list:
          if stem == 1:
              stemmed_word = ps.stem(token)
              new_tokens.append(stemmed_word)
              # to be able to map each token to the resulting stemmed word
              if token not in stemmed_dict:
                  stemmed_dict[token] = stemmed_word
          else:
              new_tokens.append(token)
  # add back in last two tokens
  new_tokens.append(tokens[-2])
  new_tokens.append(tokens[-1])
  cleaned_text = " ".join(new_tokens)
  cleaned_text = cleaned_text.replace('  ', ' ')
  return cleaned_text
```

# Dataframes

All of the article text collected is then transformed into multiple dataframe versions. One way of representing textual data within a dataframe is with binary values. In this case, each column is a token, or a word, that appears in any of the documents (articles) collected. Each row represents one document. The values are either a 0 or 1, denoting whether or not the token appears within the article. Another representation as a dataframe has the values of the dataframe as the frequencies of each token within an article. Finally, another dataframe is created with the Term Frequency-Inverse Document Frequency (TF-IDF) scores of the tokens within an article as the values. Some of these dataframes may work better than others when it comes to the predictive modeling portion of the project and revealing patterns within the text of a news source. 

```{python, include=False}
import os
from os import listdir

# we want to be in the capstone folder, not in the doc folder
os.chdir("..")
```

```{python, include=False}
pwd
```

```{python}
import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import string
from string import punctuation
from tensorflow.keras.preprocessing.text import Tokenizer

# looping through all text files to apply preprocessing functions
article_docs = []
dir = os.listdir('data/text/')
dir.sort()
for filename in dir:
    filepath = os.path.join('data/text/', filename)
    if filename.split(".")[-1] == "txt":
        article_string = file_to_string(filepath)
        new_string = clean_text(article_string, 1)
        article_docs.append(new_string)

# convert the list of article strings into a binary-value dataframe
t = Tokenizer()
t.fit_on_texts(article_docs)
encoded_docs = t.texts_to_matrix(article_docs, mode='binary')
words = [x for x in t.word_index.keys()]
binary_df = pd.DataFrame(data = encoded_docs[:, 1:], columns=words)
# List of conditions
source_conditions = [
      binary_df['abcarticle'] == 1
    , binary_df['bbcarticle'] == 1
    , binary_df['cnnarticle'] == 1
    , binary_df['foxarticle'] == 1
    , binary_df['nbcarticle'] == 1
    , binary_df['nyparticle'] == 1
    , binary_df['nytarticle'] == 1
    , binary_df['wparticle'] == 1
    , binary_df['wsjarticle'] == 1
]

# List of values to return
source_choices  = [
      "ABC News"
    , "BBC"
    , "CNN"
    , "Fox News"
    , "NBC News"
    , "New York Post"
    , "The New York Times"
    , "The Washington Post"
    , "The Wall Street Journal"
]

# List of conditions
topic_conditions = [
      binary_df['affirmativearticle'] == 1
    , binary_df['balloonarticle'] == 1
    , binary_df['bidenarticle'] == 1
    , binary_df['hamasarticle'] == 1
    , binary_df['pentagonarticle'] == 1
    , binary_df['santosarticle'] == 1
    , binary_df['tanksarticle'] == 1
    , binary_df['trumparticle'] == 1
]
# List of values to return
topic_choices  = [
      "Supreme Court Ruling on Affirmative Action"
    , "Chinese Surveillance Balloon"
    , "Biden's Low Approval Rates in Polls"
    , "The Deadliest Attack by Hamas"
    , "Pentagon Documents Leak"
    , "George Santos' Expulsion from Congress"
    , "U.S. and Germany Send Tanks to Ukraine"
    , "Trump's Indictment"
]
# create a new source column 
binary_df["article_source"] = np.select(source_conditions, source_choices, "ERROR")

# create a new topic column
binary_df["article_topic"] = np.select(topic_conditions, topic_choices, "ERROR")

# drop the token columns that identify the topic/source, not part of actual article text
binary_df.drop(columns=['abcarticle', 'bbcarticle', 'cnnarticle', 'foxarticle', 'nbcarticle',
                        'nyparticle', 'nytarticle', 'wparticle', 'wsjarticle', 'affirmativearticle',
                        'balloonarticle', 'bidenarticle', 'hamasarticle', 'pentagonarticle',
                        'santosarticle', 'tanksarticle', 'trumparticle'], inplace=True)

binary_df.head()

encoded_docs_freq = t.texts_to_matrix(article_docs, mode='count')
freq_df = pd.DataFrame(data = encoded_docs_freq[:, 1:], columns=words)
# List of conditions
source_conditions = [
      freq_df['abcarticle'] == 1
    , freq_df['bbcarticle'] == 1
    , freq_df['cnnarticle'] == 1
    , freq_df['foxarticle'] == 1
    , freq_df['nbcarticle'] == 1
    , freq_df['nyparticle'] == 1
    , freq_df['nytarticle'] == 1
    , freq_df['wparticle'] == 1
    , freq_df['wsjarticle'] == 1
]

# List of values to return
source_choices  = [
      "ABC News"
    , "BBC"
    , "CNN"
    , "Fox News"
    , "NBC News"
    , "New York Post"
    , "The New York Times"
    , "The Washington Post"
    , "The Wall Street Journal"
]

# List of conditions
topic_conditions = [
      freq_df['affirmativearticle'] == 1
    , freq_df['balloonarticle'] == 1
    , freq_df['bidenarticle'] == 1
    , freq_df['hamasarticle'] == 1
    , freq_df['pentagonarticle'] == 1
    , freq_df['santosarticle'] == 1
    , freq_df['tanksarticle'] == 1
    , freq_df['trumparticle'] == 1
]
# List of values to return
topic_choices  = [
      "Supreme Court Ruling on Affirmative Action"
    , "Chinese Surveillance Balloon"
    , "Biden's Low Approval Rates in Polls"
    , "The Deadliest Attack by Hamas"
    , "Pentagon Documents Leak"
    , "George Santos' Expulsion from Congress"
    , "U.S. and Germany Send Tanks to Ukraine"
    , "Trump's Indictment"
]
# create a new source column 
freq_df["article_source"] = np.select(source_conditions, source_choices, "ERROR")

# create a new topic column
freq_df["article_topic"] = np.select(topic_conditions, topic_choices, "ERROR")

# drop the token columns that identify the topic/source, not part of actual article text
freq_df.drop(columns=['abcarticle', 'bbcarticle', 'cnnarticle', 'foxarticle', 'nbcarticle',
                        'nyparticle', 'nytarticle', 'wparticle', 'wsjarticle', 'affirmativearticle',
                        'balloonarticle', 'bidenarticle', 'hamasarticle', 'pentagonarticle',
                        'santosarticle', 'tanksarticle', 'trumparticle'], inplace=True)

freq_df.head()

# create dataframe with tf-idf values

encoded_docs_tfidf = t.texts_to_matrix(article_docs, mode='tfidf')
tfidf_df = pd.DataFrame(data = encoded_docs_tfidf[:, 1:], columns=words)
# List of conditions
source_conditions = [
      tfidf_df['abcarticle'] != 0
    , tfidf_df['bbcarticle'] != 0
    , tfidf_df['cnnarticle'] != 0
    , tfidf_df['foxarticle'] != 0
    , tfidf_df['nbcarticle'] != 0
    , tfidf_df['nyparticle'] != 0
    , tfidf_df['nytarticle'] != 0
    , tfidf_df['wparticle'] != 0
    , tfidf_df['wsjarticle'] != 0
]

# List of values to return
source_choices  = [
      "ABC News"
    , "BBC"
    , "CNN"
    , "Fox News"
    , "NBC News"
    , "New York Post"
    , "The New York Times"
    , "The Washington Post"
    , "The Wall Street Journal"
]

# List of conditions
topic_conditions = [
      tfidf_df['affirmativearticle'] != 0
    , tfidf_df['balloonarticle'] != 0
    , tfidf_df['bidenarticle'] != 0
    , tfidf_df['hamasarticle'] != 0
    , tfidf_df['pentagonarticle'] != 0
    , tfidf_df['santosarticle'] != 0
    , tfidf_df['tanksarticle'] != 0
    , tfidf_df['trumparticle'] != 0
]
# List of values to return
topic_choices  = [
      "Supreme Court Ruling on Affirmative Action"
    , "Chinese Surveillance Balloon"
    , "Biden's Low Approval Rates in Polls"
    , "The Deadliest Attack by Hamas"
    , "Pentagon Documents Leak"
    , "George Santos' Expulsion from Congress"
    , "U.S. and Germany Send Tanks to Ukraine"
    , "Trump's Indictment"
]
# create a new source column 
tfidf_df["article_source"] = np.select(source_conditions, source_choices, "ERROR")

# create a new topic column
tfidf_df["article_topic"] = np.select(topic_conditions, topic_choices, "ERROR")

# drop the token columns that identify the topic/source, not part of actual article text
tfidf_df.drop(columns=['abcarticle', 'bbcarticle', 'cnnarticle', 'foxarticle', 'nbcarticle',
                        'nyparticle', 'nytarticle', 'wparticle', 'wsjarticle', 'affirmativearticle',
                        'balloonarticle', 'bidenarticle', 'hamasarticle', 'pentagonarticle',
                        'santosarticle', 'tanksarticle', 'trumparticle'], inplace=True)

tfidf_df.head()
```




# Exploratory Analysis

We may be interested in clustering news sources together to see which ones are most similar to each other. This can be done in a dendrogram using the TF-IDF scores of their tokens. For this purpose, a new dataframe will have to be created with each row representing not just one article, but all articles from a single source in order to have one entry per source. 

```{python}
# create a list of strings where each string is all articles from one source (for dendogram)
source_docs = []

j = 0

for i in range(9):
    # looping through each article of each source, and only taking up until and not including second to last
    # token, bc last two tokens represent the name of the source and topic of article
    # for last article, we index up until and not including only the last token bc we don't want to include
    # the topic of the article, but we do want to include the source name, which is the second to last token
    source = " ".join(article_docs[j].split()[:-2]) + " " + " ".join(article_docs[j+1].split()[:-2]) + " "\
        + " ".join(article_docs[j+2].split()[:-2]) + " " + " ".join(article_docs[j+3].split()[:-2]) + " "\
        + " ".join(article_docs[j+4].split()[:-2]) + " " + " ".join(article_docs[j+5].split()[:-2]) + " "\
        + " ".join(article_docs[j+6].split()[:-2]) + " " + " ".join(article_docs[j+7].split()[:-1])
    source_docs.append(source)
    j += 8

source_docs

# create a dataframe of token tf-idf's with each row representing all articles of one source

# convert the list of article strings into a tf-idf-value dataframe
t = Tokenizer()
t.fit_on_texts(source_docs)
encoded_source_docs = t.texts_to_matrix(source_docs, mode='tfidf')
words = [x for x in t.word_index.keys()]
tfidf_source_df = pd.DataFrame(data = encoded_source_docs[:, 1:], columns=words)
# List of conditions
source_conditions = [
      tfidf_source_df['abcarticle'] != 0
    , tfidf_source_df['bbcarticle'] != 0
    , tfidf_source_df['cnnarticle'] != 0
    , tfidf_source_df['foxarticle'] != 0
    , tfidf_source_df['nbcarticle'] != 0
    , tfidf_source_df['nyparticle'] != 0
    , tfidf_source_df['nytarticle'] != 0
    , tfidf_source_df['wparticle'] != 0
    , tfidf_source_df['wsjarticle'] != 0
]

# List of values to return
source_choices  = [
      "ABC News"
    , "BBC"
    , "CNN"
    , "Fox News"
    , "NBC News"
    , "New York Post"
    , "The New York Times"
    , "The Washington Post"
    , "The Wall Street Journal"
]

# create a new source column 
tfidf_source_df["article_source"] = np.select(source_conditions, source_choices, "ERROR")
tfidf_source_df.set_index('article_source', inplace=True) # removes article_source column and makes it the index
tfidf_source_df.drop(['abcarticle', 'bbcarticle', 'cnnarticle', 'foxarticle',
                      'nbcarticle', 'nyparticle', 'nytarticle', 'wparticle',
                      'wsjarticle'], axis=1, inplace=True)
tfidf_source_df
```


```{python}
#| label: fig-dendrogram
#| fig-cap: "A dendrogram clustering sources together using TF-IDF scores of their tokens."

# create dendrogram with complete linkage from tfidf scores df, whose rows each represent one source

from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt

Z = linkage(tfidf_source_df, 'complete')
fig = plt.figure(figsize=(14, 4))
fig.suptitle("Complete Linkage", fontsize=14)
plt.xlabel('Source', fontsize=6)
plt.yticks(fontsize = 8) 
dn = dendrogram(Z, labels=tfidf_source_df.index)
plt.xticks(fontsize = 8)
plt.show()
```

According to the dendrogram, ABC News and NBC News, as well as BBC and Fox News are the two pairs of sources that are most similar to one another. However, it's important to keep in mind that these results are based on only the small sample of articles used for each source and may not be generalizable to the sources as wholes. It is also important to keep in mind that the similarity of these sources is solely being based on the vocabulary usage of each source and not any other factors.  

Another thing that could be interesting to look at are the wordclouds for each source. On a wordcloud, the bigger the word, the more frequently it appears within the text. Looking at these could also give a sense of the difference in vocabulary between each source. This is why topic coverage was kept the same across all sources, so that comparisons like these may be made to scope out differences in wording, given that the sources are each writing about the same topics.

```{python}
# create a function to be able to make a series of wordclouds, one for each source
from wordcloud import WordCloud

def create_wordcloud(text, title):
    '''Given a string of all text and a string
    for the title, creates a wordcloud.'''
    plt.figure(figsize = (20,10))
    wc = WordCloud(colormap = "YlOrRd", background_color='white', width=1600, height=800, max_font_size = 400).generate(text)
    plt.title(title, fontsize=40)
    plt.axis("off")
    title_snake = title.lower().replace(" ", "_")
    wc.to_file(f'wordcloud_{title_snake}.png')
    #plt.savefig(f'wordcloud_{title_snake}.png', dpi = 1000)
    plt.tight_layout(pad=0)
    plt.imshow(wc)

# loop through the list of strings, each one representing all articles' text from a given source, and create the wordcloud for it. 
for i in range(len(source_docs)):
    create_wordcloud(source_docs[i], tfidf_source_df.index[i])
```

The wordclouds for each source look mostly similar, with the most common word throughout them all being "said." This is unsurprising. The only exception here is Fox News, whose most frequently appearing word throughout all the articles is "Trump." Trump is a frequently appearing word for all sources because one of the topics chosen for the articles is explicitly about Trump. However, for Fox News, it is even more commonly used than the word "said." This is interesting, but this alone should not provoke any conclusions about this source being biased towards Trump, for example. It is important to remember that all this means is that "Trump" is the word that appeared the most frequently througout Fox News' articles, which could potentially be because Fox News had the longest article about Trump. Longer articles will certainly have a higher count of words overall. This can be examined further.

```{python}
# create a list of unstemmed article document texts
# looping through all text files to apply preprocessing functions
from plotnine import *

article_docs_unstemmed = []
dir = os.listdir('data/text/')
dir.sort()
for filename in dir:
    filepath = os.path.join('data/text/', filename)
    if filename.split(".")[-1] == "txt":
        article_string = file_to_string(filepath)
        new_string = clean_text(article_string, 0)
        article_docs_unstemmed.append(new_string)

# investigating why Fox News has Trump as most frequent word, to see if it's related to length of article 

trump_article_lengths = []
trump_word_counts = []

i = 1
for article in article_docs_unstemmed:
    if i%8 == 0:
        trump_count = 0
        for word in article.split():
            if word == "trump":
                trump_count += 1
        trump_word_counts.append(trump_count)
        article_length = len(article.split())
        trump_article_lengths.append(article_length)
    i += 1

# let's do the same for the word "biden" in the biden articles and see if there are outliers 

biden_article_lengths = []
biden_word_counts = []

i = 1
for article in article_docs_unstemmed:
    if article.split()[-1] == "bidenarticle":
        biden_count = 0
        for word in article.split():
            if word == "biden":
                biden_count += 1
        biden_word_counts.append(biden_count)
        article_length = len(article.split())
        biden_article_lengths.append(article_length)
    i += 1

# create a df with sources, their trump article lengths, and the frequency of the word "trump"

trump_words = pd.DataFrame(columns=['source', 'article_length', 'trump_word_count'])
trump_words['source'] = tfidf_source_df.index
trump_words['article_length'] = trump_article_lengths
trump_words['trump_word_count'] = trump_word_counts
trump_words

biden_words = pd.DataFrame(columns=['source', 'article_length', 'biden_word_count'])
biden_words['source'] = tfidf_source_df.index
biden_words['article_length'] = biden_article_lengths
biden_words['biden_word_count'] = biden_word_counts

# create scatterplot of length of trump article vs frequency of the word "Trump"

display(
ggplot(data=trump_words,
       mapping=aes(x='article_length', y='trump_word_count', color='source'))
       + geom_point(show_legend=True)
       + geom_smooth(method = "lm", se=False, color="darkgrey")
       + labs(title="Trump Article Length vs. Mentions of Trump",
              x='# of Words in Article',
              y='# of Times "Trump" Mentioned')
)

# create scatterplot of length of biden article vs frequency of the word "Biden"

(
ggplot(data=biden_words,
       mapping=aes(x='article_length', y='biden_word_count', color='source'))
       + geom_point(show_legend=True)
       + geom_smooth(method = "lm", se=False, color="darkgrey")
       + labs(title="Biden Article Length vs. Mentions of Biden",
              x='# of Words in Article',
              y='# of Times "Biden" Mentioned')
)
```

Above we used scatterplots to see how the length of the Trump articles are related to the frequency of the word "Trump" within them, by source. We do, in fact, see that the point for Fox News is an outlier. Given its article length, it does mention Trump a lot more frequently than the Trump articles from other sources. Out of curiosity, we look at the same visualization for the word "Biden" in the Biden articles. Interestingly, Fox News again appears to be an outlier. Given its article length, it also mentions Biden a lot more frequently than the remaining sources. Now, it is not as easy to make assumptions about the partiality of Fox News just based on these word frequencies. They could be more telling of the writing styles of each source, or it could also merely be a result of using such a small sample size of articles.

# Sentiment Analysis

Next, the connotation of each article and source overall is studied. The TextBlob package in Python provides polarity and subjectivity scores for any text string. A polarity score, on a scale of [-1, 1], tells if the text has a positive or negative connotation to it. Subjectivity scores, on a scale of [0, 1] tells how opinionated or subjective a text sounds as opposed to being factual. The higher the score, the more subjective the text is. A dataframe is created that displays the polarity and subjectivity scores of each article, with various other columns being created that help place each article's score in the context of the entire corpus of documents and that will be used in following visualizations.

```{python}
# calculate polarity and subjectivity scores, create dataframe
from textblob import TextBlob

scores_df = pd.DataFrame({'source':tfidf_df['article_source'], 'topic':tfidf_df['article_topic']})

scores_df['source'] = np.where(scores_df['source'] == "The New York Times", "New York Times", scores_df['source'])
scores_df['source'] = np.where(scores_df['source'] == "The Washington Post", "Washington Post", scores_df['source'])
scores_df['source'] = np.where(scores_df['source'] == "The Wall Street Journal", "Wall Street Journal", scores_df['source'])

polarity_scores = []
subjectivity_scores = []

for article in article_docs_unstemmed:
    polarity_scores.append(round(TextBlob(" ".join(article.split()[:-2])).sentiment.polarity, 2))
    subjectivity_scores.append(round(TextBlob(" ".join(article.split()[:-2])).sentiment.subjectivity, 2))

scores_df['polarity_score'] = polarity_scores
scores_df['subjectivity_score'] = subjectivity_scores

average_topic_polarity_scores = []
average_source_polarity_scores = []

for topic in scores_df['topic'].value_counts().index:
    mean_score = round(scores_df[scores_df['topic'] == topic]['polarity_score'].mean(), 2)
    average_topic_polarity_scores.append(mean_score)

for source in scores_df['source'].value_counts().index:
    mean_score = round(scores_df[scores_df['source'] == source]['polarity_score'].mean(), 2)
    for i in range(8):
        average_source_polarity_scores.append(mean_score)

scores_df['average_polarity_for_topic'] = average_topic_polarity_scores * 9
scores_df['average_polarity_for_source'] = average_source_polarity_scores

average_topic_subjectivity_scores = []
average_source_subjectivity_scores = []

for topic in scores_df['topic'].value_counts().index:
    mean_score = round(scores_df[scores_df['topic'] == topic]['subjectivity_score'].mean(), 2)
    average_topic_subjectivity_scores.append(mean_score)

for source in scores_df['source'].value_counts().index:
    mean_score = round(scores_df[scores_df['source'] == source]['subjectivity_score'].mean(), 2)
    for i in range(8):
        average_source_subjectivity_scores.append(mean_score)

scores_df['average_subjectivity_for_topic'] = average_topic_subjectivity_scores * 9
scores_df['average_subjectivity_for_source'] = average_source_subjectivity_scores

scores_df['polarity_diff_from_topic_mean'] = scores_df['polarity_score'] - scores_df['average_polarity_for_topic']
scores_df['subjectivity_diff_from_topic_mean'] = scores_df['subjectivity_score'] - scores_df['average_subjectivity_for_topic']
scores_df['polarity_diff_from_source_mean'] = scores_df['polarity_score'] - scores_df['average_polarity_for_source']
scores_df['subjectivity_diff_from_source_mean'] = scores_df['subjectivity_score'] - scores_df['average_subjectivity_for_source']

sources_polarity_dev = []

for source in scores_df['source'].value_counts().index:
    total_dev = scores_df[scores_df['source'] == source]['polarity_diff_from_topic_mean'].sum()
    for i in range(8):
        sources_polarity_dev.append(total_dev/8)

sources_subjectivity_dev = []

for source in scores_df['source'].value_counts().index:
    total_dev = scores_df[scores_df['source'] == source]['subjectivity_diff_from_topic_mean'].sum()
    for i in range(8):
        sources_subjectivity_dev.append(total_dev/8)

scores_df['average_source_polarity_deviation_from_topic_mean'] = sources_polarity_dev
scores_df['average_source_subjectivity_deviation_from_topic_mean'] = sources_subjectivity_dev

scores_df['polarity_sign'] = np.where(scores_df['polarity_score'] > 0, 'pos', 'neg')
scores_df['polarity_magnitude'] = abs(scores_df['polarity_score'])

scores_df.head(5)
```

Since the documentation of the calculation of these scores is limited, one may wonder if they are somehow related. That is, are polarity scores related to subjectivity scores in some way? A scatterplot is created to see if a higher polarity score magnitude (absolute value) may mean a higher subjectivity score as well.

```{python}
# to better understand subjectivity scores: are polarity scores and subjectivity scores correlated?
# this may suggest that polarity score is used in the calculation of a subjectivity score

(
ggplot(scores_df, aes(x="polarity_magnitude", y="subjectivity_score", color='topic'))
+ geom_point()
+ labs(x="Absolute Value of Polarity Score",
       y='Subjectivity Score',
       title='Are Polarity Score Magnitudes Correlated with Subjectivity Scores?')
)
```

There does not appear to be a linear or any other sort of relationship between the polarity and subjectivity scores of the articles used in this project. However, the graph does show almost a cluster of points of the same color, telling that the articles about the Supreme Court ruling against affirmative action tend to have stronger polarity scores. The same graph may be visualized colored by source instead, to see if any clusters of sources are observed.


```{python}
(
ggplot(scores_df, aes(x="polarity_magnitude", y="subjectivity_score", color='source'))
+ geom_point()
+ labs(x="Absolute Value of Polarity Score",
       y='Subjectivity Score',
       title='Are Polarity Score Magnitudes Correlated with Subjectivity Scores?')
)
```



## Quarto is cool

This section was copy/pasted from various parts of the [Quarto website](https://quarto.org/docs/get-started/hello/vscode.html).

:::{.callout-note}
Note that there are five types of callouts, including:
`note`, `tip`, `warning`, `caution`, and `important`.
:::

:::{.callout-tip}
## Tip With Caption

This is an example of a callout with a caption.
:::


For your reference, here's an example of a Python code cell in Quarto, along with a figure that gets generated, along with a caption and a label so that it can be referred to automatically as "Figure 1" (or whatever) in the writeup.

For a demonstration of a line plot on a polar axis, see @fig-polar.

```{python}
#| label: fig-polar
#| fig-cap: "A line plot on a polar axis"

import numpy as np
import matplotlib.pyplot as plt

r = np.arange(0, 2, 0.01)
theta = 2 * np.pi * r
fig, ax = plt.subplots(
  subplot_kw = {'projection': 'polar'} 
)
ax.plot(theta, r)
ax.set_rticks([0.5, 1, 1.5, 2])
ax.grid(True)
plt.show()
```

Here's an example of citing a source [see @phil99, pp. 33-35]. Be sure the source information is entered in "BibTeX" form in the `references.bib` file.


The bibliography will automatically get generated. Any sources you cite in the document will be included. Other entries in the `.bib` file will not be included.